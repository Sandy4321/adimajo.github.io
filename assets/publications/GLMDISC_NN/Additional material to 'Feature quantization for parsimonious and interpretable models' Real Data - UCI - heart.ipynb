{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG2rOyfcuS51"
   },
   "source": [
    "# Loading real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKQFa3L9uS52"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.metrics\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Nov  6 10:06:52 2018\n",
    "\n",
    "@author: yandexdataschool\n",
    "\n",
    "Original Code found in:\n",
    "https://github.com/yandexdataschool/roc_comparison\n",
    "\n",
    "updated: Raul Sanchez-Vazquez\n",
    "\"\"\"\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def compute_midrank_weight(x, sample_weight):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    cumulative_weight = np.cumsum(sample_weight[J])\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = cumulative_weight[i:j].mean()\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    T2[J] = T\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count, sample_weight):\n",
    "    if sample_weight is None:\n",
    "        return fastDeLong_no_weights(predictions_sorted_transposed, label_1_count)\n",
    "    else:\n",
    "        return fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight)\n",
    "\n",
    "\n",
    "def fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank_weight(positive_examples[r, :], sample_weight[:m])\n",
    "        ty[r, :] = compute_midrank_weight(negative_examples[r, :], sample_weight[m:])\n",
    "        tz[r, :] = compute_midrank_weight(predictions_sorted_transposed[r, :], sample_weight)\n",
    "    total_positive_weights = sample_weight[:m].sum()\n",
    "    total_negative_weights = sample_weight[m:].sum()\n",
    "    pair_weights = np.dot(sample_weight[:m, np.newaxis], sample_weight[np.newaxis, m:])\n",
    "    total_pair_weights = pair_weights.sum()\n",
    "    aucs = (sample_weight[:m]*(tz[:, :m] - tx)).sum(axis=1) / total_pair_weights\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / total_negative_weights\n",
    "    v10 = 1. - (tz[:, m:] - ty[:, :]) / total_positive_weights\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def fastDeLong_no_weights(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating\n",
    "              Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth, sample_weight):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    if sample_weight is None:\n",
    "        ordered_sample_weight = None\n",
    "    else:\n",
    "        ordered_sample_weight = sample_weight[order]\n",
    "\n",
    "    return order, label_1_count, ordered_sample_weight\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
    "        ground_truth, sample_weight)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32072,
     "status": "ok",
     "timestamp": 1538123582048,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "",
      "userId": "06833975693225147439"
     },
     "user_tz": -120
    },
    "id": "Vb0y8P0KvDDC",
    "outputId": "3fb7c753-0ea0-4963-d91a-75b524fa9b52"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heart = pd.read_csv(\"drive/My Drive/Discrétisation ICLR19/data_iclr19/heart.csv\",sep=\";\",na_values=['#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan', 'null','.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxF5gphPuS55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "column_names = ['age',\n",
    "                'sex',\n",
    "                'cp',\n",
    "                'trestbps',\n",
    "                'chol',\n",
    "                'fbs',\n",
    "                'restecg',\n",
    "                'thalach',\n",
    "                'exang',\n",
    "                'oldpeak',\n",
    "                'slope',\n",
    "                'ca',\n",
    "                'thal',\n",
    "                'num']\n",
    "\n",
    "heart = pd.read_csv(\n",
    "    \"~/Google Drive/Discrétisation ICLR19/opendata/heart.dat\",\n",
    "    sep=\"\\s\",\n",
    "    names = column_names,\n",
    "    header= None,\n",
    "    index_col = False,\n",
    "    na_values=[\n",
    "        '#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "        '.'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.num = heart.num-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGeDXBovFNpb"
   },
   "outputs": [],
   "source": [
    "heart.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey_WW8EkFNpx"
   },
   "outputs": [],
   "source": [
    "heart.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes = np.where(heart['restecg'].astype(str)=='1.0')\n",
    "heart.drop(heart.index[lignes], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8unEBe--uS59"
   },
   "source": [
    "# Establishing 1st benchmark: naïve logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZZidiG7uS6N"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CST_74HuS6b"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urgkKgbK3-xk"
   },
   "outputs": [],
   "source": [
    "heart_label_encoders = []\n",
    "\n",
    "heart_encoded = heart.copy()\n",
    "\n",
    "for j in [\n",
    "        'cp', 'restecg', 'slope', 'thal'\n",
    "]:\n",
    "    temp = sk.preprocessing.LabelEncoder()\n",
    "    temp.fit(heart[j].astype(str))\n",
    "    heart_label_encoders.append(temp)\n",
    "    heart_encoded[j] = temp.transform(heart[j].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLK8k1FukVRy"
   },
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp6MivXdk7ZK"
   },
   "outputs": [],
   "source": [
    "heart_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "heart_one_hot_encoder.fit(heart_encoded[[\n",
    "        'cp', 'restecg', 'slope', 'thal'\n",
    "]])\n",
    "heart_one_hot_encoded = heart_encoded.copy()\n",
    "heart_one_hot_encoded.drop(\n",
    "        ['cp', 'restecg', 'slope', 'thal'],\n",
    "    axis=1,\n",
    "    inplace=True)\n",
    "heart_one_hot_encoded = pd.concat(\n",
    "    [\n",
    "        heart_one_hot_encoded,\n",
    "        pd.DataFrame(\n",
    "            heart_one_hot_encoder.transform(heart_encoded[[\n",
    "        'cp', 'restecg', 'slope', 'thal'\n",
    "            ]]),\n",
    "            index=heart_one_hot_encoded.index)\n",
    "    ],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbtYe1QcuS6O"
   },
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpyvBQ5yyguG"
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZG3E0cduS6P"
   },
   "outputs": [],
   "source": [
    "heart_features_train, heart_features_test, heart_perf_train, heart_perf_test = sk.model_selection.train_test_split(\n",
    "    heart_one_hot_encoded.drop('num', axis=1),\n",
    "    heart_one_hot_encoded.num,\n",
    "    test_size=0.33,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmQ_Qyc7FNtt"
   },
   "outputs": [],
   "source": [
    "heart_nn_features_train = heart_encoded.iloc[\n",
    "    heart_features_train.index, :].drop(\n",
    "        'num', axis=1)\n",
    "heart_nn_features_test = heart_encoded.iloc[heart_features_test.index, :].drop(\n",
    "    'num', axis=1)\n",
    "heart_nn_perf_train = heart_encoded.iloc[\n",
    "    heart_features_train.index, :].num\n",
    "heart_nn_perf_test = heart_encoded.iloc[heart_features_test.index, :].num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V25o2mnLuS6m"
   },
   "source": [
    "### LR on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSInu6RZu1In"
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4033,
     "status": "ok",
     "timestamp": 1538123633392,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "",
      "userId": "06833975693225147439"
     },
     "user_tz": -120
    },
    "id": "Qx139VZfuS6n",
    "outputId": "35cec94c-273d-4a43-e214-3e4cd6527703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=1e-08, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_naive_LR = sk.linear_model.LogisticRegression(C=1e20, tol=1e-8, solver=\"newton-cg\")\n",
    "heart_naive_LR.fit(\n",
    "    heart_features_train[heart_features_train.isna().sum(axis=1) == 0],\n",
    "    heart_perf_train[heart_features_train.isna().sum(axis=1) == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMPUPbOiWwBC"
   },
   "source": [
    "### Application of learnt LR on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1538123643056,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "",
      "userId": "06833975693225147439"
     },
     "user_tz": -120
    },
    "id": "UxknKgYpWu8f",
    "outputId": "3423083f-beec-4e25-8e41-2ff381345833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803030303030303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * sk.metrics.roc_auc_score(\n",
    "    heart_perf_test,\n",
    "    heart_naive_LR.predict_proba(heart_features_test)[:, 1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.8030303030303028\n",
      "AUC COV: 0.000957835773326836\n",
      "95% Gini CI: [0.68171276 0.92434785]\n"
     ]
    }
   ],
   "source": [
    "alpha = .95\n",
    "y_pred = heart_naive_LR.predict_proba(heart_features_test)[:, 1]\n",
    "y_true = heart_perf_test\n",
    "\n",
    "auc, auc_cov = delong_roc_variance(\n",
    "    y_true,\n",
    "    y_pred)\n",
    "\n",
    "auc_std = np.sqrt(auc_cov)\n",
    "lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "\n",
    "ci = stats.norm.ppf(\n",
    "    lower_upper_q,\n",
    "    loc=auc,\n",
    "    scale=auc_std)\n",
    "\n",
    "ci[ci > 1] = 1\n",
    "\n",
    "print('Gini:', 2*auc-1)\n",
    "print('AUC COV:', auc_cov)\n",
    "print('95% Gini CI:', 2*ci-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lltm03RFFNux"
   },
   "source": [
    "# Establishing 2nd benchmark: MDLP disc + Chi2 grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KakuZgryFNuy"
   },
   "source": [
    "## MDLP disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHT84QcIFNuz"
   },
   "outputs": [],
   "source": [
    "from mdlp.discretization import MDLP\n",
    "transformer_cont_heart = MDLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BLWiHfKFNu-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDLP(continuous_features=None, min_depth=0, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_cont_heart.fit(\n",
    "    heart_nn_features_train[[\n",
    "        'age','sex','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','ca'\n",
    "    ]], heart_nn_perf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_heart_MDLP_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "score_heart_MDLP_one_hot_encoder.fit(\n",
    "    transformer_cont_heart.transform(heart_nn_features_train[[\n",
    "        'age','sex','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','ca'\n",
    "    ]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpiqEx5iFNvg"
   },
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test(liste):\n",
    "    try:\n",
    "        return sp.stats.chi2_contingency(liste)[1]\n",
    "    except Exception:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature cp - levels merged : ['2.0', '3.0']\n",
      "Feature cp - levels merged : ['2.0 - 3.0', '1.0']\n",
      "Feature slope - levels merged : ['2.0', '3.0']\n",
      "Feature thal - levels merged : ['7.0', '6.0']\n"
     ]
    }
   ],
   "source": [
    "heart_train_grouped = heart.iloc[heart_features_train.index, :].copy()\n",
    "d = dict((x, []) for x in ['cp', 'restecg', 'slope', 'thal'])\n",
    "\n",
    "for var in ['cp', 'restecg', 'slope', 'thal']:\n",
    "    \n",
    "    heart_train_grouped[var] = heart_train_grouped[var].astype(str)\n",
    "    d[var] = [x for x in np.unique(heart_train_grouped[var])]\n",
    "    p_value = 1\n",
    "\n",
    "    while(p_value>0.05):\n",
    "        if len(np.unique(heart_train_grouped[var]))>1:\n",
    "            freq_table = heart_train_grouped.groupby([var,'num']).size().reset_index()\n",
    "            liste_paires_modalites = [[a,b] for a in np.unique(heart_train_grouped[var]) for b in np.delete(np.unique(heart_train_grouped[var]),np.where(np.unique(heart_train_grouped[var])==a))]\n",
    "            liste_chi2 = [chi2_test([freq_table.iloc[np.in1d(freq_table[var],pair[0]),2],freq_table.iloc[np.in1d(freq_table[var],pair[1]),2]]) for pair in liste_paires_modalites]\n",
    "            p_value = max(liste_chi2)\n",
    "        else: break\n",
    "\n",
    "        if (p_value>0.05 and len(np.unique(heart_train_grouped[var]))>1):\n",
    "            heart_train_grouped[var].iloc[np.in1d(heart_train_grouped[var],liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))])] = liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0] + ' - ' + liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1]\n",
    "            d[var].remove(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0])\n",
    "            d[var].remove(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1])\n",
    "            d[var].append(str(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0] + ' - ' + liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1]))\n",
    "            print('Feature '+var+ ' - levels merged : '+str(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))]))\n",
    "        else: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_ikEvzAFNvj"
   },
   "source": [
    "## Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_train_mdlp = score_heart_MDLP_one_hot_encoder.transform(\n",
    "    transformer_cont_heart.transform(heart_nn_features_train[[\n",
    "        'age','sex','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','ca'\n",
    "    ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_train_grouped_label_encoders = []\n",
    "\n",
    "heart_train_grouped_encoded = heart_train_grouped.copy()\n",
    "\n",
    "for j in ['cp', 'restecg', 'slope', 'thal']:\n",
    "    temp = sk.preprocessing.LabelEncoder()\n",
    "    temp.fit(heart_train_grouped_encoded[j].astype(str))\n",
    "    heart_train_grouped_label_encoders.append(temp)\n",
    "    heart_train_grouped_encoded[j] = temp.transform(heart_train_grouped_encoded[j].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_heart_CHI2_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "\n",
    "score_heart_CHI2_one_hot_encoder.fit(\n",
    "        heart_train_grouped_encoded[[\n",
    "                    'cp', 'restecg', 'slope', 'thal'\n",
    "\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_train_chi2 = score_heart_CHI2_one_hot_encoder.transform(heart_train_grouped_encoded[[\n",
    "                    'cp', 'restecg', 'slope', 'thal'\n",
    "\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_adhoc_train = np.concatenate((heart_train_chi2,heart_train_mdlp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=1e-08, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_adhoc_LR = sk.linear_model.LogisticRegression(C=1e20, tol=1e-8, solver=\"newton-cg\")\n",
    "heart_adhoc_LR.fit(\n",
    "    heart_adhoc_train,\n",
    "    heart_train_grouped_encoded['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_test_grouped = heart.iloc[heart_features_test.index, :].copy()\n",
    "\n",
    "for var in ['cp', 'restecg', 'slope', 'thal']:\n",
    "    \n",
    "    heart_test_grouped[var] = heart_test_grouped[var].astype(str)\n",
    "\n",
    "    for x in d[var]:\n",
    "        if x.find(' - ')>-1:\n",
    "            liste_modalites = x.split(' - ')\n",
    "            heart_test_grouped[var].iloc[np.in1d(heart_test_grouped[var],liste_modalites)] = x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_test_grouped_encoded = heart_test_grouped.copy()\n",
    "\n",
    "for j in ['cp', 'restecg', 'slope', 'thal']:\n",
    "    indice = ['cp', 'restecg', 'slope', 'thal'].index(j)\n",
    "    heart_test_grouped_encoded[j] = heart_train_grouped_label_encoders[indice].transform(heart_test_grouped_encoded[j].astype(str))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_test_chi2 = score_heart_CHI2_one_hot_encoder.transform(heart_test_grouped_encoded[[\n",
    "                    'cp', 'restecg', 'slope', 'thal'\n",
    "\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_test_mdlp = score_heart_MDLP_one_hot_encoder.transform(\n",
    "    transformer_cont_heart.transform(heart_nn_features_test[[\n",
    "        'age','sex','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','ca'\n",
    "    ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_adhoc_test = np.concatenate(\n",
    "    (heart_test_chi2, heart_test_mdlp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868686868686869"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * sk.metrics.roc_auc_score(\n",
    "    heart_test_grouped_encoded['num'],\n",
    "    heart_adhoc_LR.predict_proba(heart_adhoc_test)[:, 1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.7868686868686869\n",
      "AUC COV: 0.001113544107549969\n",
      "95% Gini CI: [0.65606144 0.91767593]\n"
     ]
    }
   ],
   "source": [
    "alpha = .95\n",
    "y_pred = heart_adhoc_LR.predict_proba(heart_adhoc_test)[:, 1]\n",
    "y_true = heart_test_grouped_encoded['num']\n",
    "\n",
    "auc, auc_cov = delong_roc_variance(\n",
    "    y_true,\n",
    "    y_pred)\n",
    "\n",
    "auc_std = np.sqrt(auc_cov)\n",
    "lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "\n",
    "ci = stats.norm.ppf(\n",
    "    lower_upper_q,\n",
    "    loc=auc,\n",
    "    scale=auc_std)\n",
    "\n",
    "ci[ci > 1] = 1\n",
    "\n",
    "print('Gini:', 2*auc-1)\n",
    "print('AUC COV:', auc_cov)\n",
    "print('95% Gini CI:', 2*ci-1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ICLR 2019 - Additional material to 'Discretization and levels merging for logistic regression via shallow neural networks' Experiment Real Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
