{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG2rOyfcuS51"
   },
   "source": [
    "# Loading real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iYSvQZrLP5U"
   },
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKQFa3L9uS52"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.metrics\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdEBQKXz_xko"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Nov  6 10:06:52 2018\n",
    "\n",
    "@author: yandexdataschool\n",
    "\n",
    "Original Code found in:\n",
    "https://github.com/yandexdataschool/roc_comparison\n",
    "\n",
    "updated: Raul Sanchez-Vazquez\n",
    "\"\"\"\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def compute_midrank_weight(x, sample_weight):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    cumulative_weight = np.cumsum(sample_weight[J])\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = cumulative_weight[i:j].mean()\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    T2[J] = T\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count, sample_weight):\n",
    "    if sample_weight is None:\n",
    "        return fastDeLong_no_weights(predictions_sorted_transposed, label_1_count)\n",
    "    else:\n",
    "        return fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight)\n",
    "\n",
    "\n",
    "def fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank_weight(positive_examples[r, :], sample_weight[:m])\n",
    "        ty[r, :] = compute_midrank_weight(negative_examples[r, :], sample_weight[m:])\n",
    "        tz[r, :] = compute_midrank_weight(predictions_sorted_transposed[r, :], sample_weight)\n",
    "    total_positive_weights = sample_weight[:m].sum()\n",
    "    total_negative_weights = sample_weight[m:].sum()\n",
    "    pair_weights = np.dot(sample_weight[:m, np.newaxis], sample_weight[np.newaxis, m:])\n",
    "    total_pair_weights = pair_weights.sum()\n",
    "    aucs = (sample_weight[:m]*(tz[:, :m] - tx)).sum(axis=1) / total_pair_weights\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / total_negative_weights\n",
    "    v10 = 1. - (tz[:, m:] - ty[:, :]) / total_positive_weights\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def fastDeLong_no_weights(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating\n",
    "              Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth, sample_weight):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    if sample_weight is None:\n",
    "        ordered_sample_weight = None\n",
    "    else:\n",
    "        ordered_sample_weight = sample_weight[order]\n",
    "\n",
    "    return order, label_1_count, ordered_sample_weight\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
    "        ground_truth, sample_weight)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vb0y8P0KvDDC"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502,
     "status": "error",
     "timestamp": 1547548225671,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "https://lh6.googleusercontent.com/-YaHJkcitxbk/AAAAAAAAAAI/AAAAAAAAAC8/lVJxYfcygtE/s64/photo.jpg",
      "userId": "06833975693225147439"
     },
     "user_tz": -60
    },
    "id": "VxF5gphPuS55",
    "outputId": "24b92894-2bdf-4fb2-f1c3-b114db72a97a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e5f97c2f9fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#url_train = '~/Google Drive/Discrétisation ICLR19/opendata/adult.data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#url_test = '~/Google Drive/Discrétisation ICLR19/opendata/adult.test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\\s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\\s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[1;32m   1058\u001b[0m                                      engine=engine))\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[1;32m   2073\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/Discrétisation ICLR19/opendata/adult.data'"
     ]
    }
   ],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status', 'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "import pandas as pd\n",
    "url_train = 'drive/My Drive/Discrétisation ICLR19/opendata/adult.data'\n",
    "url_test = 'drive/My Drive/Discrétisation ICLR19/opendata/adult.test'\n",
    "#url_train = '~/Google Drive/Discrétisation ICLR19/opendata/adult.data'\n",
    "#url_test = '~/Google Drive/Discrétisation ICLR19/opendata/adult.test'\n",
    "train = pd.read_csv(url_train, sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
    "train\n",
    "test = pd.read_csv(url_test, sep=\",\\s\", header=None, names = column_names, engine = 'python', skiprows=1)\n",
    "test['income'].replace(regex=True,inplace=True,to_replace=r'\\.',value=r'')\n",
    "adult = pd.concat([test,train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 330,
     "status": "error",
     "timestamp": 1547548209907,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "https://lh6.googleusercontent.com/-YaHJkcitxbk/AAAAAAAAAAI/AAAAAAAAAC8/lVJxYfcygtE/s64/photo.jpg",
      "userId": "06833975693225147439"
     },
     "user_tz": -60
    },
    "id": "I3kTKL8N7ojp",
    "outputId": "057a7d24-c18b-4f0f-bb73-a3e9410b4704"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9a9742ad7a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0madult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fnlwgt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'educational-num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult' is not defined"
     ]
    }
   ],
   "source": [
    "adult.income = sklearn.preprocessing.LabelEncoder().fit_transform(adult.income)\n",
    "\n",
    "adult.drop(['fnlwgt','educational-num'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 467,
     "status": "error",
     "timestamp": 1547548210595,
     "user": {
      "displayName": "Adrien Ehrhardt",
      "photoUrl": "https://lh6.googleusercontent.com/-YaHJkcitxbk/AAAAAAAAAAI/AAAAAAAAAC8/lVJxYfcygtE/s64/photo.jpg",
      "userId": "06833975693225147439"
     },
     "user_tz": -60
    },
    "id": "Ey_WW8EkFNpx",
    "outputId": "3512f407-997a-49d6-a6fe-c56d928be365"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2aa674f8791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult' is not defined"
     ]
    }
   ],
   "source": [
    "adult.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8unEBe--uS59"
   },
   "source": [
    "# Establishing 1st benchmark: naïve logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZZidiG7uS6N"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CST_74HuS6b"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urgkKgbK3-xk"
   },
   "outputs": [],
   "source": [
    "adult_label_encoders = []\n",
    "\n",
    "adult_encoded = adult.copy()\n",
    "\n",
    "for j in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender']:\n",
    "    temp = sk.preprocessing.LabelEncoder()\n",
    "    temp.fit(adult[j].astype(str))\n",
    "    adult_label_encoders.append(temp)\n",
    "    adult_encoded[j] = temp.transform(adult[j].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLK8k1FukVRy"
   },
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xgb-_cvK-9V"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp6MivXdk7ZK"
   },
   "outputs": [],
   "source": [
    "adult_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "adult_one_hot_encoder.fit(adult_encoded[[\n",
    "    'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "]])\n",
    "adult_one_hot_encoded = adult_encoded.copy()\n",
    "adult_one_hot_encoded.drop(\n",
    "    ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'],\n",
    "    axis=1,\n",
    "    inplace=True)\n",
    "adult_one_hot_encoded = pd.concat(\n",
    "    [\n",
    "        adult_one_hot_encoded,\n",
    "        pd.DataFrame(\n",
    "            adult_one_hot_encoder.transform(adult_encoded[[\n",
    "                'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "            ]]),\n",
    "            index=adult_one_hot_encoded.index)\n",
    "    ],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbtYe1QcuS6O"
   },
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpyvBQ5yyguG"
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZG3E0cduS6P"
   },
   "outputs": [],
   "source": [
    "adult_features_train, adult_features_test, adult_perf_train, adult_perf_test = sk.model_selection.train_test_split(\n",
    "    adult_one_hot_encoded.drop('income', axis=1),\n",
    "    adult_one_hot_encoded.income,\n",
    "    test_size=0.33,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmQ_Qyc7FNtt"
   },
   "outputs": [],
   "source": [
    "adult_nn_features_train = adult_encoded.iloc[\n",
    "    adult_features_train.index, :].drop(\n",
    "        'income', axis=1)\n",
    "adult_nn_features_test = adult_encoded.iloc[adult_features_test.index, :].drop(\n",
    "    'income', axis=1)\n",
    "adult_nn_perf_train = adult_encoded.iloc[\n",
    "    adult_features_train.index, :].income\n",
    "adult_nn_perf_test = adult_encoded.iloc[adult_features_test.index, :].income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V25o2mnLuS6m"
   },
   "source": [
    "### LR on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSInu6RZu1In"
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qx139VZfuS6n",
    "outputId": "1d758d9a-2670-4fe4-c2a9-79bd14b1cae9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:462: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:462: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:462: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=1e-08, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_naive_LR = sk.linear_model.LogisticRegression(C=1e20, tol=1e-8, solver=\"newton-cg\")\n",
    "adult_naive_LR.fit(\n",
    "    adult_features_train[adult_features_train.isna().sum(axis=1) == 0],\n",
    "    adult_perf_train[adult_features_train.isna().sum(axis=1) == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMPUPbOiWwBC"
   },
   "source": [
    "### Application of learnt LR on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxknKgYpWu8f",
    "outputId": "3f3edbd6-8c95-4a1e-d309-18a218cba9b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150530331027663"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_LR = sk.metrics.roc_auc_score(\n",
    "    adult_perf_test,\n",
    "    adult_naive_LR.predict_proba(adult_features_test)[:, 1])\n",
    "2 * AUC_LR - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFja-6kF-zmb",
    "outputId": "28ed140e-cf46-4385-f8fb-4c1f5775c986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.8150530331027666\n",
      "AUC COV: 6.096126731962454e-06\n",
      "95% Gini CI: [0.8053746  0.82473147]\n"
     ]
    }
   ],
   "source": [
    "alpha = .95\n",
    "y_pred = adult_naive_LR.predict_proba(adult_features_test)[:, 1]\n",
    "y_true = adult_perf_test\n",
    "\n",
    "auc, auc_cov = delong_roc_variance(\n",
    "    y_true,\n",
    "    y_pred)\n",
    "\n",
    "auc_std = np.sqrt(auc_cov)\n",
    "lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "\n",
    "ci = stats.norm.ppf(\n",
    "    lower_upper_q,\n",
    "    loc=auc,\n",
    "    scale=auc_std)\n",
    "\n",
    "ci[ci > 1] = 1\n",
    "\n",
    "print('Gini:', 2*auc-1)\n",
    "print('AUC COV:', auc_cov)\n",
    "print('95% Gini CI:', 2*ci-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9M67JV1-krJ"
   },
   "outputs": [],
   "source": [
    "#import math\n",
    "\n",
    "#Q1 = AUC_LR / (2-AUC_LR)\n",
    "\n",
    "#Q2 = 2*AUC_LR**2 / (1+AUC_LR)\n",
    "\n",
    "#SE_AUC = math.sqrt((AUC_LR*(1-AUC_LR) + (sum(adult_perf_test)-1)*(Q1-AUC_LR**2) + ((adult_perf_test.shape[0]-sum(adult_perf_test))-1)*(Q2-AUC_LR**2))/((adult_perf_test.shape[0]-sum(adult_perf_test))*sum(adult_perf_test)))\n",
    "\n",
    "#AUC_LR + 1.96*SE_AUC\n",
    "#AUC_LR - 1.96*SE_AUC\n",
    "\n",
    "#2*(AUC_LR + 1.96*SE_AUC)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kr1ioEP2_iKl"
   },
   "outputs": [],
   "source": [
    "#2*(AUC_LR - 1.96*SE_AUC)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3QuFJ20_pNA"
   },
   "outputs": [],
   "source": [
    "#2*1.96*SE_AUC*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lltm03RFFNux"
   },
   "source": [
    "# Establishing 2nd benchmark: MDLP disc + Chi2 grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KakuZgryFNuy"
   },
   "source": [
    "## MDLP disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHT84QcIFNuz"
   },
   "outputs": [],
   "source": [
    "#!pip install mdlp-discretization\n",
    "from mdlp.discretization import MDLP\n",
    "transformer_cont_adult = MDLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BLWiHfKFNu-",
    "outputId": "8724b460-b3f8-471a-a6cd-8e04de5ca337"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDLP(continuous_features=None, min_depth=0, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_cont_adult.fit(\n",
    "    adult_nn_features_train[[\n",
    "        'age','capital-gain','capital-loss','hours-per-week'\n",
    "    ]], adult_nn_perf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JzuUkmEHzek"
   },
   "outputs": [],
   "source": [
    "#np.unique(transformer_cont_adult.transform(\n",
    "#    adult_nn_features_test[[\n",
    "#        'age','capital-gain','capital-loss','hours-per-week'\n",
    "#    ]])[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNeVbqKo7olJ",
    "outputId": "79294b4b-ec24-4c24-9f8f-552de932f072"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_adult_MDLP_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "score_adult_MDLP_one_hot_encoder.fit(\n",
    "    transformer_cont_adult.transform(adult_nn_features_train[[\n",
    "        'age','capital-gain','capital-loss','hours-per-week'\n",
    "    ]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpiqEx5iFNvg"
   },
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPbrM7hh7olK"
   },
   "outputs": [],
   "source": [
    "def chi2_test(liste):\n",
    "    try:\n",
    "        return sp.stats.chi2_contingency(liste)[1]\n",
    "    except Exception:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8zbVujw7olL",
    "outputId": "b91a1cd1-50fa-4f29-eab8-d06aeab543f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature workclass - levels merged : ['?', 'Never-worked']\n",
      "Feature workclass - levels merged : ['Local-gov', 'Self-emp-not-inc']\n",
      "Feature workclass - levels merged : ['Private', 'Without-pay']\n",
      "Feature workclass - levels merged : ['Local-gov - Self-emp-not-inc', 'State-gov']\n",
      "Feature education - levels merged : ['10th', '5th-6th']\n",
      "Feature education - levels merged : ['10th - 5th-6th', '7th-8th']\n",
      "Feature education - levels merged : ['Doctorate', 'Prof-school']\n",
      "Feature education - levels merged : ['1st-4th', 'Preschool']\n",
      "Feature education - levels merged : ['11th', '9th']\n",
      "Feature education - levels merged : ['10th - 5th-6th - 7th-8th', '12th']\n",
      "Feature education - levels merged : ['Assoc-acdm', 'Assoc-voc']\n",
      "Feature education - levels merged : ['11th - 9th', '10th - 5th-6th - 7th-8th - 12th']\n",
      "Feature education - levels merged : ['11th - 9th - 10th - 5th-6th - 7th-8th - 12th', '1st-4th - Preschool']\n",
      "Feature marital-status - levels merged : ['Divorced', 'Married-spouse-absent']\n",
      "Feature marital-status - levels merged : ['Married-AF-spouse', 'Married-civ-spouse']\n",
      "Feature marital-status - levels merged : ['Separated', 'Widowed']\n",
      "Feature occupation - levels merged : ['Farming-fishing', 'Machine-op-inspct']\n",
      "Feature occupation - levels merged : ['Armed-Forces', 'Sales']\n",
      "Feature occupation - levels merged : ['Protective-serv', 'Tech-support']\n",
      "Feature occupation - levels merged : ['Other-service', 'Priv-house-serv']\n",
      "Feature occupation - levels merged : ['?', 'Farming-fishing - Machine-op-inspct']\n",
      "Feature occupation - levels merged : ['Armed-Forces - Sales', 'Protective-serv - Tech-support']\n",
      "Feature occupation - levels merged : ['Transport-moving', 'Craft-repair']\n",
      "Feature relationship - levels merged : ['Husband', 'Wife']\n",
      "Feature native-country - levels merged : ['?', 'Holand-Netherlands']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands', 'Honduras']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands - Honduras', 'Outlying-US(Guam-USVI-etc)']\n",
      "Feature native-country - levels merged : ['Canada', 'Yugoslavia']\n",
      "Feature native-country - levels merged : ['Hong', 'Thailand']\n",
      "Feature native-country - levels merged : ['Laos', 'Peru']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands - Honduras - Outlying-US(Guam-USVI-etc)', 'Hong - Thailand']\n",
      "Feature native-country - levels merged : ['Guatemala', 'Trinadad&Tobago']\n",
      "Feature native-country - levels merged : ['China', 'Ireland']\n",
      "Feature native-country - levels merged : ['Ecuador', 'El-Salvador']\n",
      "Feature native-country - levels merged : ['Jamaica', 'Portugal']\n",
      "Feature native-country - levels merged : ['France', 'India']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands - Honduras - Outlying-US(Guam-USVI-etc) - Hong - Thailand', 'Hungary']\n",
      "Feature native-country - levels merged : ['Scotland', 'South']\n",
      "Feature native-country - levels merged : ['Mexico', 'Nicaragua']\n",
      "Feature native-country - levels merged : ['Cambodia', 'Canada - Yugoslavia']\n",
      "Feature native-country - levels merged : ['Cambodia - Canada - Yugoslavia', 'Philippines']\n",
      "Feature native-country - levels merged : ['Haiti', 'Jamaica - Portugal']\n",
      "Feature native-country - levels merged : ['Cuba', 'Japan']\n",
      "Feature native-country - levels merged : ['Laos - Peru', 'Vietnam']\n",
      "Feature native-country - levels merged : ['England', 'Italy']\n",
      "Feature native-country - levels merged : ['Laos - Peru - Vietnam', 'Mexico - Nicaragua']\n",
      "Feature native-country - levels merged : ['Cambodia - Canada - Yugoslavia - Philippines', 'China - Ireland']\n",
      "Feature native-country - levels merged : ['Columbia', 'Laos - Peru - Vietnam - Mexico - Nicaragua']\n",
      "Feature native-country - levels merged : ['England - Italy', 'Iran']\n",
      "Feature native-country - levels merged : ['England - Italy - Iran', 'Taiwan']\n",
      "Feature native-country - levels merged : ['England - Italy - Iran - Taiwan', 'Greece']\n",
      "Feature native-country - levels merged : ['Germany', 'United-States']\n",
      "Feature native-country - levels merged : ['Poland', 'Scotland - South']\n",
      "Feature native-country - levels merged : ['Haiti - Jamaica - Portugal', 'Puerto-Rico']\n",
      "Feature native-country - levels merged : ['Columbia - Laos - Peru - Vietnam - Mexico - Nicaragua', 'Dominican-Republic']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands - Honduras - Outlying-US(Guam-USVI-etc) - Hong - Thailand - Hungary', 'Germany - United-States']\n",
      "Feature native-country - levels merged : ['Ecuador - El-Salvador', 'Guatemala - Trinadad&Tobago']\n",
      "Feature native-country - levels merged : ['Cambodia - Canada - Yugoslavia - Philippines - China - Ireland', 'Cuba - Japan']\n",
      "Feature native-country - levels merged : ['? - Holand-Netherlands - Honduras - Outlying-US(Guam-USVI-etc) - Hong - Thailand - Hungary - Germany - United-States', 'Poland - Scotland - South']\n",
      "Feature native-country - levels merged : ['Cambodia - Canada - Yugoslavia - Philippines - China - Ireland - Cuba - Japan', 'England - Italy - Iran - Taiwan - Greece']\n",
      "Feature native-country - levels merged : ['Ecuador - El-Salvador - Guatemala - Trinadad&Tobago', 'Haiti - Jamaica - Portugal - Puerto-Rico']\n",
      "Feature race - levels merged : ['Asian-Pac-Islander', 'White']\n",
      "Feature race - levels merged : ['Black', 'Other']\n",
      "Feature race - levels merged : ['Amer-Indian-Eskimo', 'Black - Other']\n"
     ]
    }
   ],
   "source": [
    "adult_train_grouped = adult.iloc[adult_features_train.index, :].copy()\n",
    "d = dict((x, []) for x in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'])\n",
    "\n",
    "for var in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender']:\n",
    "    \n",
    "    adult_train_grouped[var] = adult_train_grouped[var].astype(str)\n",
    "    d[var] = [x for x in np.unique(adult_train_grouped[var])]\n",
    "    p_value = 1\n",
    "\n",
    "    while(p_value>0.05):\n",
    "        freq_table = adult_train_grouped.groupby([var,'income']).size().reset_index()\n",
    "        liste_paires_modalites = [[a,b] for a in np.unique(adult_train_grouped[var]) for b in np.delete(np.unique(adult_train_grouped[var]),np.where(np.unique(adult_train_grouped[var])==a))]\n",
    "        liste_chi2 = [chi2_test([freq_table.iloc[np.in1d(freq_table[var],pair[0]),2],freq_table.iloc[np.in1d(freq_table[var],pair[1]),2]]) for pair in liste_paires_modalites]\n",
    "        p_value = max(liste_chi2)\n",
    "\n",
    "        if (p_value>0.05 and len(np.unique(adult_train_grouped[var]))>1):\n",
    "            adult_train_grouped[var].iloc[np.in1d(adult_train_grouped[var],liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))])] = liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0] + ' - ' + liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1]\n",
    "            d[var].remove(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0])\n",
    "            d[var].remove(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1])\n",
    "            d[var].append(str(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][0] + ' - ' + liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))][1]))\n",
    "            print('Feature '+var+ ' - levels merged : '+str(liste_paires_modalites[np.argmax(np.equal(liste_chi2,p_value))]))\n",
    "        else: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_ikEvzAFNvj"
   },
   "source": [
    "## Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5AmRphU7olO"
   },
   "outputs": [],
   "source": [
    "adult_train_mdlp = score_adult_MDLP_one_hot_encoder.transform(\n",
    "    transformer_cont_adult.transform(adult_nn_features_train[[\n",
    "        'age','capital-gain','capital-loss','hours-per-week'\n",
    "    ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWiyff8e7olP"
   },
   "outputs": [],
   "source": [
    "adult_train_grouped_label_encoders = []\n",
    "\n",
    "adult_train_grouped_encoded = adult_train_grouped.copy()\n",
    "\n",
    "for j in [\n",
    "        'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "]:\n",
    "    temp = sk.preprocessing.LabelEncoder()\n",
    "    temp.fit(adult_train_grouped_encoded[j].astype(str))\n",
    "    adult_train_grouped_label_encoders.append(temp)\n",
    "    adult_train_grouped_encoded[j] = temp.transform(adult_train_grouped_encoded[j].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gyf5dX0M7olR",
    "outputId": "97d017e2-cc19-4593-eaad-4b1008e10422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_adult_CHI2_one_hot_encoder = sk.preprocessing.OneHotEncoder(categories='auto',sparse=False,handle_unknown=\"ignore\")\n",
    "\n",
    "score_adult_CHI2_one_hot_encoder.fit(\n",
    "        adult_train_grouped_encoded[[\n",
    "            'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUNMAviK7olT"
   },
   "outputs": [],
   "source": [
    "adult_train_chi2 = score_adult_CHI2_one_hot_encoder.transform(adult_train_grouped_encoded[[\n",
    "            'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWcC8n8S7olV"
   },
   "outputs": [],
   "source": [
    "adult_adhoc_train = np.concatenate((adult_train_chi2,adult_train_mdlp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vn0OGHiS7olY",
    "outputId": "8e05a119-2efa-498c-8c45-0aa4fc606224"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=1e-08, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_adhoc_LR = sk.linear_model.LogisticRegression(C=1e20, tol=1e-8, solver=\"newton-cg\")\n",
    "adult_adhoc_LR.fit(\n",
    "    adult_adhoc_train,\n",
    "    adult_train_grouped_encoded['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7x5BNuLaD38z",
    "outputId": "4f823a33-8dfd-46f7-f391-795a1c6aed9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "adult_test_grouped = adult.iloc[adult_features_test.index, :].copy()\n",
    "\n",
    "for var in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender']:\n",
    "    \n",
    "    adult_test_grouped[var] = adult_test_grouped[var].astype(str)\n",
    "\n",
    "    for x in d[var]:\n",
    "        if x.find(' - ')>-1:\n",
    "            liste_modalites = x.split(' - ')\n",
    "            adult_test_grouped[var].iloc[np.in1d(adult_test_grouped[var],liste_modalites)] = x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQ_O7NY4D380"
   },
   "outputs": [],
   "source": [
    "adult_test_grouped_encoded = adult_test_grouped.copy()\n",
    "\n",
    "for j in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender']:\n",
    "    indice = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'].index(j)\n",
    "    adult_test_grouped_encoded[j] = adult_train_grouped_label_encoders[indice].transform(adult_test_grouped_encoded[j].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wW2sti22D382"
   },
   "outputs": [],
   "source": [
    "adult_test_chi2 = score_adult_CHI2_one_hot_encoder.transform(adult_test_grouped_encoded[[\n",
    "            'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race','gender'\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1I4R1carD383"
   },
   "outputs": [],
   "source": [
    "adult_adhoc_test = np.concatenate((adult_test_chi2,adult_test_mdlp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdoaWd_KD383",
    "outputId": "325fa929-8912-4757-ec9f-037e631dbd6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530011392408037"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_LR = sk.metrics.roc_auc_score(\n",
    "    adult_perf_test,\n",
    "    adult_adhoc_LR.predict_proba(adult_adhoc_test)[:, 1])\n",
    "2 * AUC_LR - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6ANCIBNCtzP",
    "outputId": "83c963a1-a119-4896-c37e-d95de2c941b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.8530011392408037\n",
      "AUC COV: 4.693540700382635e-06\n",
      "95% Gini CI: [0.84450878 0.8614935 ]\n"
     ]
    }
   ],
   "source": [
    "alpha = .95\n",
    "y_pred = adult_adhoc_LR.predict_proba(adult_adhoc_test)[:, 1]\n",
    "y_true = adult.iloc[adult_features_test.index, :]['income']\n",
    "\n",
    "auc, auc_cov = delong_roc_variance(\n",
    "    y_true,\n",
    "    y_pred)\n",
    "\n",
    "auc_std = np.sqrt(auc_cov)\n",
    "lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "\n",
    "ci = stats.norm.ppf(\n",
    "    lower_upper_q,\n",
    "    loc=auc,\n",
    "    scale=auc_std)\n",
    "\n",
    "ci[ci > 1] = 1\n",
    "\n",
    "print('Gini:', 2*auc-1)\n",
    "print('AUC COV:', auc_cov)\n",
    "print('95% Gini CI:', 2*ci-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8VT0IWi7oln"
   },
   "outputs": [],
   "source": [
    "#AUC_adhoc = sk.metrics.roc_auc_score(\n",
    "#    adult_grouped_encoded.iloc[adult_features_test.index, :]\n",
    "#              ['income'],\n",
    "#    adult_adhoc_LR.predict_proba(adult_adhoc_test)[:, 1])\n",
    "#2 * AUC_adhoc - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gF6OOEQAVir"
   },
   "outputs": [],
   "source": [
    "#Q1 = AUC_adhoc / (2-AUC_adhoc)\n",
    "\n",
    "#Q2 = 2*AUC_adhoc**2 / (1+AUC_adhoc)\n",
    "\n",
    "#SE_AUC = math.sqrt((AUC_adhoc*(1-AUC_adhoc) + (sum(adult_perf_test)-1)*(Q1-AUC_adhoc**2) + ((adult_perf_test.shape[0]-sum(adult_perf_test))-1)*(Q2-AUC_adhoc**2))/((adult_perf_test.shape[0]-sum(adult_perf_test))*sum(adult_perf_test)))\n",
    "\n",
    "#2 * AUC_adhoc - 1 + 2*1.96*SE_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1K3wPK-xy-s"
   },
   "outputs": [],
   "source": [
    "def hyperparam_opt_choice():\n",
    "  \n",
    "    #opt_choice = {{choice([optimizers.SGD, optimizers.RMSprop, optimizers.Adagrad, optimizers.Adadelta, optimizers.Adam, optimizers.Adamax, optimizers.Nadam])}}\n",
    "    opt_choice = {{choice([optimizers.SGD, optimizers.RMSprop])}}\n",
    "\n",
    "    if opt_choice == optimizers.SGD:\n",
    "        lr_sgd = {{uniform(0.001,2)}}\n",
    "        momentum_sgd = {{uniform(0,0.5)}}\n",
    "        decay_sgd = {{uniform(0,0.001)}}\n",
    "        nesterov_sgd = {{choice([True, False])}}\n",
    "        opt = opt_choice(lr_sgd,momentum_sgd,decay_sgd,nesterov_sgd)\n",
    "    elif opt_choice == optimizers.RMSprop:\n",
    "        lr_RMS = {{uniform(0.001,2)}}\n",
    "        decay_RMS = {{uniform(0,0.001)}}\n",
    "        rho_RMS = {{uniform(0.7,1)}}\n",
    "        epsilon_RMS = None\n",
    "        opt = opt_choice(lr_RMS,decay_RMS,rho_RMS,epsilon_RMS)\n",
    "    elif opt_choice == optimizers.Adagrad:\n",
    "        lr_adagrad = {{}}\n",
    "        epsilon_adagrad = {{}}\n",
    "        decay_adagrad = {{}}\n",
    "        opt = opt_choice(lr_adagrad,epsilon_adagrad,decay_adagrad)\n",
    "    elif opt_choice == optimizers.Adadelta:\n",
    "        lr_adadelta = {{}}\n",
    "        rho_adadelta = {{}}\n",
    "        epsilon_adadelta = {{}}\n",
    "        decay_adadelta = {{}}\n",
    "        opt = opt_choice(lr_adadelta,rho_adadelta,epsilon_adadelta,decay_adadelta)\n",
    "    elif opt_choice == optimizers.Adam:\n",
    "        lr_adam = {{}}\n",
    "        beta_1_adam = {{}}\n",
    "        beta_2_adam = {{}}\n",
    "        epsilon_adam = {{}}\n",
    "        decay_adam = {{}}\n",
    "        amsgrad_adam = {{}}\n",
    "        opt = opt_choice(lr_adam,beta_1_adam,beta_2_adam,epsilon_adam,decay_adam,amsgrad_adam)\n",
    "    elif opt_choice == optimizers.Adamax:\n",
    "        lr_adamax = {{}}\n",
    "        beta_1_adamax = {{}}\n",
    "        beta_2_adamax = {{}}\n",
    "        epsilon_adamax = {{}}\n",
    "        decay_adamax = {{}}\n",
    "        opt = opt_choice(lr_adamax,beta_1_adamax,beta_2_adamax,epsilon_adamax,decay_adamax)\n",
    "    elif opt_choice == optimizers.Nadam:\n",
    "        lr_nadam = {{}}\n",
    "        beta_1_nadam = {{}}\n",
    "        beta_2_nadam = {{}}\n",
    "        epsilon_nadam = {{}}\n",
    "        schedule_decay_nadam = {{}}\n",
    "        opt = opt_choice(lr_nadam,beta_1_nadam,beta_2_nadam,schedule_decay_nadam)\n",
    "      \n",
    "    return (opt)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ICML 2019 - Additional material to _Discretization and levels merging for logistic regression via shallow neural networks_ Real Data UCI - adult.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
